应用程序为了从Kafka中读取数据，会使用KafkaConsumer订阅Kafka的主题，然后就可以从这些主题中接收到消息。从Kafka读取数据和其他消息读取数据有点不同，有一些概念需要事先弄清楚，否则就对如何使用消费者API不知所措。下面我们会先解释一些重要的概念，然后通过示例的方式展示消费API的不同用法，从而实现不同的需求。

### 消费者概念  
为了更好的理解如何从Kafka中读取数据，首先你需要理解消费者和消费者组。下面的小节将会涉及这些概念。  

#### 消费者和消费者组  
假设你的应用程序要从Kafka的一个主题中读取消息，对消息进行验证，然后将结果写入到其他存储系统中。你的做法会是：创建一个消费者对象，订阅指定的主题，然后开始接收消息、数据验证、结果输出。这种做法在一段时间内可能工作的很好，但是如果生产者写入消息的速度超过应用程序执行验证逻辑的速度怎么办？如果你只有一个消费者负责读取和处理数据，消费者的读取进度最终会越来越跟不上生产者的写入进度，很显然我们需要对主题的消费进行扩展。就像多个生产者可以写到同一个主题一样，我们应该允许多个消费者同时从一个主题读取数据：通过将数据进行分离，每个消费者只负责一部分数据，达到负载均衡的目的。  

Kafka的消费者通常都属于某一个消费组的一部分，当多个消费者订阅了一个主题并且属于同一个消费组，那么消费组中的每个消费者都会接收到主题的不同子集分区。  

我们假设主题T1有4个分区，现在，假设我们创建了一个新的消费者C1，并且它是消费组G1的唯一成员，使用消费者C1订阅主题T1。消费者C1会获取到T1所有4个分区的消息。见图4-1。  
![image](/Images/Kafka/consumer-and-consumer-groups-1.png)  

如果我们添加另一个消费者C2到消费组G1，现在每个消费者只会各自得到两个分区的消息。可能分区0和分区2的消息会到C1，分区1和分区3的消息会到C2。见图4-2。  
![image](/Images/Kafka/consumer-and-consumer-groups-2.png)  

如果消费者组G1有4个消费者，那么每个消费者都会读取一个分区的消息。见图4-3.  
![image](/Images/Kafka/consumer-and-consumer-groups-3.png)  

如果我们添加比已有分区数量更多的消费者到一个消费者组中消费同一个主题，那么有一些消费者就会空闲而得不到任何消息。见图4-4。  
![image](/Images/Kafka/consumer-and-consumer-groups-4.png)

我们扩展Kafka主题数据的消费能力的主要解决方法是为消费者组增加更多的消费者。Kafka消费者通常会做一些延迟较高的操作，比如写入数据库或者做一些耗时的数据计算。这种情况下，单一消费者的消费能力无法跟上数据流入Kafka主题的速度，所以增加更多的消费者，通过让每个消费者只拥有分区和消息的子集一起共享负载，是我们扩展消费能力主要方法。因此为主题创建更多分区是一个好的设计——它允许在负载增加的时候可以增加更多的消费者。不过注意，消费者的数量大于主题的分区数是没有任何意义的——否则有些消费者会一直处于空闲状态。第2章中为如何选择一个主题的分区数提供了一些建议。  

除了通过添加消费者来扩展单一的应用程序外，多个应用程序需要从同一个主题中读取数据也是很常见。实际上Kafka的一个设计目标就是确保数据生产到Kafka的主题后，对多个应用场景都是可用的。这种情况下，我们希望每个应用程序都能够得到所有的消息，而不是消息子集。为了确保一个应用程序得到主题的所有消息，应该保证每个应用程序都有单独的消费者组。不同于很多传统的消息系统，Kafka可以在不牺牲性能的前提下大规模扩展地消费者和消费者组。  

在前面的示例中，如果我们新添加一个只有一个消费者的消费者组G2，那么G2中的这个消费者就会得到主题T1的所有消息，而它和消费组G1在做什么事情毫无关系。消费者组G2也可以拥有多个消费者，每个消费者也可以获得所有分区的一个子集，就像我们前面所说的G1一样，但是从整体上来说消费组G2仍然会得到所有的消息，而不会受其他消费者组的影响。  
![image](/Images/Kafka/consumer-and-consumer-groups-5.png)  

总结下上面的操作过程，你为每个需要读取一个或多个主题所有消息的应用程序都创建了新的消费组，然后为已有的消费组添加消费者来动态地扩展从主题中读取和处理消息的能力，那么每个新增加的消费者都只能得到消息的子集。  

#### 消费者组平衡  


### 创建一个消费者  




### 订阅主题  




### The Poll Loop  




### 配置消费者  




#### fetch.min.bytes  




#### fetch.max.wait.ms  





#### max.partition.fetch.bytes  





#### session.timeout.ms  




#### auto.offset.reset  




#### enable.auto.commit  





#### partition.assignment.strategy  




#### client.id  




#### max.poll.records  





#### receive.buffer.bytes和send.buffer.bytes



### Commits和Offsets  


#### 自动提交  



#### 提交当前的Offset  


#### 异步提交  



#### 同步合并和异步提交  



#### 提交指定的Offset  




### Rebalance监听器  




### 消费指定Offset的记录  






### 如何退出  



### 反序列化器  




#### 自定义反序列化器  




#### 使用Avro反序列化Kafka Consumer  





### 独立的Consumer：为什么和如何不使用带有group的Consumer  





### 旧的Consumer APIs  




### 总结
