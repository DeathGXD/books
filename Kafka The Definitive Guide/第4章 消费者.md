应用程序为了从Kafka中读取数据，会使用KafkaConsumer订阅Kafka的主题，然后就可以从这些主题中接收到消息。从Kafka读取数据和其他消息读取数据有点不同，有一些概念需要事先弄清楚，否则就对如何使用消费者API不知所措。下面我们会先解释一些重要的概念，然后通过示例的方式展示消费API的不同用法，从而实现不同的需求。

### 消费者概念  
为了更好的理解如何从Kafka中读取数据，首先你需要理解消费者和消费者组。下面的小节将会涉及这些概念。  

#### 消费者和消费者组  
假设你的应用程序要从Kafka的一个主题中读取消息，对消息进行验证，然后将结果写入到其他存储系统中。你的做法会是：创建一个消费者对象，订阅指定的主题，然后开始接收消息、数据验证、结果输出。这种做法在一段时间内可能工作的很好，但是如果生产者写入消息的速度超过应用程序执行验证逻辑的速度怎么办？如果你只有一个消费者负责读取和处理数据，消费者的读取进度最终会越来越跟不上生产者的写入进度，很显然我们需要对主题的消费进行扩展。就像多个生产者可以写到同一个主题一样，我们应该允许多个消费者同时从一个主题读取数据：通过将数据进行分离，每个消费者只负责一部分数据，达到负载均衡的目的。  

Kafka的消费者通常都属于某一个消费组的一部分，当多个消费者订阅了一个主题并且属于同一个消费组，那么消费组中的每个消费者都会接收到主题的不同子集分区。  

我们假设主题T1有4个分区，现在，假设我们创建了一个新的消费者C1，并且它是消费组G1的唯一成员，使用消费者C1订阅主题T1。消费者C1会获取到T1所有4个分区的消息。见图4-1。  
![image](/Images/Kafka/consumer-and-consumer-groups-1.png)  

如果我们添加另一个消费者C2到消费组G1，现在每个消费者只会各自得到两个分区的消息。可能分区0和分区2的消息会到C1，分区1和分区3的消息会到C2。见图4-2。  
![image](/Images/Kafka/consumer-and-consumer-groups-2.png)  

如果消费者组G1有4个消费者，那么每个消费者都会读取一个分区的消息。见图4-3.  
![image](/Images/Kafka/consumer-and-consumer-groups-3.png)  

如果我们添加比已有分区数量更多的消费者到一个消费者组中消费同一个主题，那么有一些消费者就会空闲而得不到任何消息。见图4-4。  
![image](/Images/Kafka/consumer-and-consumer-groups-4.png)

我们扩展Kafka主题数据的消费能力的主要解决方法是为消费者组增加更多的消费者。Kafka消费者通常会做一些延迟较高的操作，比如写入数据库或者做一些耗时的数据计算。这种情况下，单一消费者的消费能力无法跟上数据流入Kafka主题的速度，所以增加更多的消费者，通过让每个消费者只拥有分区和消息的子集一起共享负载，是我们扩展消费能力主要方法。因此为主题创建更多分区是一个好的设计——它允许在负载增加的时候可以增加更多的消费者。不过注意，消费者的数量大于主题的分区数是没有任何意义的——否则有些消费者会一直处于空闲状态。第2章中为如何选择一个主题的分区数提供了一些建议。  

除了通过添加消费者来扩展单一的应用程序外，多个应用程序需要从同一个主题中读取数据也是很常见。实际上Kafka的一个设计目标就是确保数据生产到Kafka的主题后，对多个应用场景都是可用的。这种情况下，我们希望每个应用程序都能够得到所有的消息，而不是消息子集。为了确保一个应用程序得到主题的所有消息，应该保证每个应用程序都有单独的消费者组。不同于很多传统的消息系统，Kafka可以在不牺牲性能的前提下大规模扩展地消费者和消费者组。  

在前面的示例中，如果我们新添加一个只有一个消费者的消费者组G2，那么G2中的这个消费者就会得到主题T1的所有消息，而它和消费组G1在做什么事情毫无关系。消费者组G2也可以拥有多个消费者，每个消费者也可以获得所有分区的一个子集，就像我们前面所说的G1一样，但是从整体上来说消费组G2仍然会得到所有的消息，而不会受其他消费者组的影响。  
![image](/Images/Kafka/consumer-and-consumer-groups-5.png)  

总结下上面的操作过程，你为每个需要读取一个或多个主题所有消息的应用程序都创建了新的消费组，然后为已有的消费组添加消费者来动态地扩展从主题中读取和处理消息的能力，那么每个新增加的消费者都只能得到消息的子集。  

#### 消费者组平衡  
上面我们看到了消费组中的消费者共享了它们所订阅的主题的分区。当为消费组添加新消费者时，它会从之前其他消费者消费的分区开始消费消息。同样当发生消费者关闭、进程挂掉、离开消费组，它所使用的分区就会被其他剩余的消费者所消费。为消费者重新分配分区同样也会发生在消费组订阅的主题被修改时，比如管理员会添加一个新的分区。  

分区的所有权从一个消费者转移给另一个消费者，这个事件叫做平衡（rebalance）。平衡操作的重要性不言而喻，因为它提供了消费组的高可用、可扩展性（允许我们添加或删除消费者变得简单和安全），但对于事件的处理则有点不受欢迎。在平衡期间，消费者不能消费消息，所以平衡实际上造成了消费组短暂的不可用窗口。另外，当分区从一个消费者转移到另一个消费者时会丢失当前的状态，如果它缓存了数据的话，就需要重新刷新缓存，这会使得我们的应用程序响应变慢，知道消费者重新恢复到正常的状态。本章我们会讨论如何安全地处理平衡操作，并且怎么避免不必要的平衡。  

消费者为了维护它们在消费组中的成员地位，以及分配给它们的分区所有权，是通过发送心跳给被指定为消费组协调者（Group Coordinator）的一个Kafka代理（Broker），注意这个代理对于不同的消费组都是不同的。只要消费者能够在正常的时间间隔内发送心跳，它就会被认为是存活的、运行良好，就可以处理分区的消息。实际上消费者轮询消息的动作就是消费者发送心跳的原因。如果消费者很长时间没有发送心跳，它的会话会超时（服务端的协调者会保持每个消费者的连接会话），协调者就会认为消费者挂掉，从而触发一次平衡操作。注意如果消费者自己崩溃并且停止处理消息，协调者会在数秒之后判断消费者没有心跳，才决定它挂掉了并且触发平衡。在这数秒的时间段内，被挂掉消费者拥有的分区上不会处理任何消息。而如果是优雅地关闭一个消费者时，消费者会通知消费组说它正在离开，协调者就会立即触发平衡，从而减少了消息无法被处理的间隙。本章的后面我们会讨论一些关于控制心跳频率、会话超时的配置，以及如何设置它们来匹配我们的需求。  

为消费者分配Partition是怎么工作的？
当一个消费者想要加入一个消费组，它会发送JoinGroup请求给消费组的协调者，第一个加入消费组的消费者会成为组的领导者（Leader）。领导者会从协调者接收到所有的消费者（包括最近发送了心跳，被认为是存活的所有消费者），并且负责为每个消费者分配分区子集。它会使用PartitionAssignor接口来决定哪个消费者应用处理哪些分区。Kafka内置了两种分区分配策略，后面在配置部分会详细介绍。在决定了分区分配之后，领导者发送每个消费者的分配列表给协调者，协调者会发送这些分配信息给所有的消费者。每个消费者只会看到它自己的分配结果。领导者是唯一有所有消费者列表和它们的分配信息的客户端进程。上面这个过程在每次平衡操作发生时都会重复执行。  



### 创建一个消费者  
消费者开始消费记录的第一步是创建一个KafkaConsumer实例，创建KafkaConsumer类似于创建KafkaProducer，首先创建一个Properties实例，传递消费者的配置属性。本章后面我们会讨论所有的属性，这里只需要三个必须的属性：bootstrap.servers、key.deserializer和value.deserializer。
第一个属性bootstrap.servers指向Kafka集群的连接地址，它和KafkaProducer的使用方式一样。剩余的两个属性key.deserializer和value.deserializer和生产者的serializers类似。
还有一个属性group.id不是必须的，但现在我们假设它是必须的。group.id指定了KafkaConsumer实例所属的消费组。虽然创建不属于任何消费组的消费者也是可行的，但这种情况很少见，所以本章我们都会假设消费者是消费组的一部分。下面的代码实例了如何创建一个KafkaConsumer：  
```java
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
```  
如果你读过第三章创建生产者的代码，你会发现这里看到的大部分代码都很熟悉。我们打算消费的消息格式都是字符串类型（反序列化：Kafka中存储的是二进制字节类型，Kafka内部会负责将字节类型转换为字符串类型，所以消费者读取到的消息是字符串类型），所以我们使用了内置的StringDeserializer反序列化器，最后创建的KafkaConsumer泛型类型也是字符串（KafkaConsumer类上的两个泛型类型分别表示消息的键值类型）。只有group.id这个属性可能你没见过，它表示的是这个消费者（作为消费组的一部分）所属的消费组名称。  

### 订阅主题  
一旦创建完消费组实例，下一步是让消费者订阅一个或多个主题。subscribe()方法会将多个主题的列表作为一个参数，使用起来非常简单，下面的代码创建了只有一个元素的列表，订阅的主题名称叫做”customerCountries”。  
```java
consumer.subscribe(Collections.singletonList("customerCountries"));
```  
也可以使用正则表达式调用subscribe()方法，如果有人创建了和正则表达式匹配的新主题，平衡操作基本上会立即发生，消费者就会从新主题中立即开始消费。这种方式对于需要从多个主题消费消息的应用程序非常有用，这样就可以处理不同主题包含的不同类型的数据。为了订阅所有的test主题，调用方式如下：  
```java
consumer.subscribe("test.*");
```  

### 轮询循环  
消费者应用程序编程接口（API）的核心是一个简单的循环，会负责从服务端拉取更多的数据。一旦消费者订阅了主题，轮询循环会处理所有的协调细节、分区平衡、心跳、数据获取。返回给开发者的只是很简洁的API，仅仅返回分配分区的可用数据。消费者客户端代码的主体如下：  
```java
try {
  while (true) { //1
    ConsumerRecords<String, String> records = consumer.poll(100); //2
    for (ConsumerRecord<String, String> record : records) { //3
      log.debug("topic=%s,partition=%s,offset=%d,customer=%s,country=%s\n",
        record.topic(), record.partition(),
        record.offset(), record.key(), record.value());

      int updatedCount = 1;
      if (custCountryMap.countainsValue(record.value())) {
        updatedCount = custCountryMap.get(record.value()) + 1;
      }
      custCountryMap.put(record.value(), updatedCount)

      JSONObject json = new JSONObject(custCountryMap);
      System.out.println(json.toString(4)) //4
    }
  }
} finally {
  consumer.close(); //5
}
```  
这里确实是一个死循环，消费者通常都是长时间运行的应用程序，会持续从Kafka中拉取数据。后面我们会展示如何干净地退出循环，并且关闭消费者。
这一行是本章最重要的一行代码。就像鲨鱼要么保持不断游动要么死亡，消费者必须一直轮询Kafka，否则就会被认为挂掉了，就会导致消费的分区被组中其他的消费者继续处理。
poll()方法返回一批记录集。每条记录会包含这条记录来源于哪个主题和分区、这条记录在分区中的偏移量、当然还有这条记录的键值。通常我们会迭代列表，并且处理每一条单机的记录。poll()方法也可以接受一个超时时间参数，表示执行轮询最多花费多长时间，不管轮询的结果有没有数据。这个超时值通常由应用程序是否需要快速响应来决定，也就是你要在轮询之后多快返回对主线程的控制（消费者的轮询是单线程阻塞的，所以如果想要尽快在拉取到消息后马上处理，可以缩短超时时间，当时间超过后，轮询结束，就可以执行消息处理逻辑）。
消息处理通常最后会写入到数据存储系统或者更新已有的记录。本例的目标是为了跟踪每个国家的顾客数量，所以我们更新了字典表然后将结果打印为JSON字符串，实际应用中一般会将更新记录写入到存储系统中。
总是在退出时执行close()方法。这会关闭网络连接和Socket，并且会立即触发平衡操作，而不是让协调者来发现消费者可能因为挂掉而没有及时发送心跳，那样会等待更长的时间，也会导致分区子集的消息在更长的时间内不能被任何消费者所消费。  

轮询操作不仅仅做了获取数据这个工作。当新的消费者第一次调用poll()方法时，它会负责找到协调者、加入消费组、接收到分配的分区。如果需要做平衡操作，也是在poll()方法中处理的。当然用来表示消费者存活状态的心跳请求也是在poll()中发送的。基于这些原因，我们要确保迭代处理消息时要足够快速和高效。
注意：你不能在一个线程中拥有属于同一个消费者的多个消费者，而且也不能在同一个消费者中使用多线程。一个线程对应一个消费者是最基本的原则（这里的线程指的是主线程，而不是消费者中的拉取线程，一个消费者实际上是可以有多个拉取线程的）。
在一个应用程序中如果要处理同一个消费组的多个消费者，你需要保证每个消费者运行在自己的线程中。通常将消费者逻辑保证成自定义的对象，然后使用Java的ExecutorService来启动各自的消费者线程。




### 配置消费者  




#### fetch.min.bytes  




#### fetch.max.wait.ms  





#### max.partition.fetch.bytes  





#### session.timeout.ms  




#### auto.offset.reset  




#### enable.auto.commit  





#### partition.assignment.strategy  




#### client.id  




#### max.poll.records  





#### receive.buffer.bytes和send.buffer.bytes



### 提交和偏移量  


#### 自动提交  



#### 提交当前的Offset  


#### 异步提交  



#### 结合同步和异步提交  



#### 提交指定的Offset  




### Rebalance监听器  




### 消费指定Offset的记录  






### 如何退出  



### 反序列化器  




#### 自定义反序列化器  




#### 使用Avro反序列化Kafka Consumer  





### 独立的Consumer：为什么和如何不使用带有group的Consumer  





### 旧的Consumer APIs  




### 总结
