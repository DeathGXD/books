应用程序为了从Kafka中读取数据，会使用KafkaConsumer订阅Kafka的主题，然后就可以从这些主题中接收到消息。从Kafka读取数据和其他消息读取数据有点不同，有一些概念需要事先弄清楚，否则就对如何使用消费者API不知所措。下面我们会先解释一些重要的概念，然后通过示例的方式展示消费API的不同用法，从而实现不同的需求。

### 消费者概念  
为了更好的理解如何从Kafka中读取数据，首先你需要理解消费者和消费者组。下面的小节将会涉及这些概念。  

#### 消费者和消费者组  
假设你的应用程序要从Kafka的一个主题中读取消息，对消息进行验证，然后将结果写入到其他存储系统中。你的做法会是：创建一个消费者对象，订阅指定的主题，然后开始接收消息、数据验证、结果输出。这种做法在一段时间内可能工作的很好，但是如果生产者写入消息的速度超过应用程序执行验证逻辑的速度怎么办？如果你只有一个消费者负责读取和处理数据，消费者的读取进度最终会越来越跟不上生产者的写入进度，很显然我们需要对主题的消费进行扩展。就像多个生产者可以写到同一个主题一样，我们应该允许多个消费者同时从一个主题读取数据：通过将数据进行分离，每个消费者只负责一部分数据，达到负载均衡的目的。  

Kafka的消费者通常都属于某一个消费组的一部分，当多个消费者订阅了一个主题并且属于同一个消费组，那么消费组中的每个消费者都会接收到主题的不同子集分区。  

我们假设主题T1有4个分区，现在，假设我们创建了一个新的消费者C1，并且它是消费组G1的唯一成员，使用消费者C1订阅主题T1。消费者C1会获取到T1所有4个分区的消息。见图4-1。  
![image](/Images/Kafka/consumer-and-consumer-groups-1.png)  

如果我们添加另一个消费者C2到消费组G1，现在每个消费者只会各自得到两个分区的消息。可能分区0和分区2的消息会到C1，分区1和分区3的消息会到C2。见图4-2。  
![image](/Images/Kafka/consumer-and-consumer-groups-2.png)  

如果消费者组G1有4个消费者，那么每个消费者都会读取一个分区的消息。见图4-3.  
![image](/Images/Kafka/consumer-and-consumer-groups-3.png)  

如果我们添加比已有分区数量更多的消费者到一个消费者组中消费同一个主题，那么有一些消费者就会空闲而得不到任何消息。见图4-4。  
![image](/Images/Kafka/consumer-and-consumer-groups-4.png)

我们扩展Kafka主题数据的消费能力的主要解决方法是为消费者组增加更多的消费者。Kafka消费者通常会做一些延迟较高的操作，比如写入数据库或者做一些耗时的数据计算。这种情况下，单一消费者的消费能力无法跟上数据流入Kafka主题的速度，所以增加更多的消费者，通过让每个消费者只拥有分区和消息的子集一起共享负载，是我们扩展消费能力主要方法。因此为主题创建更多分区是一个好的设计——它允许在负载增加的时候可以增加更多的消费者。不过注意，消费者的数量大于主题的分区数是没有任何意义的——否则有些消费者会一直处于空闲状态。第2章中为如何选择一个主题的分区数提供了一些建议。  

除了通过添加消费者来扩展单一的应用程序外，多个应用程序需要从同一个主题中读取数据也是很常见。实际上Kafka的一个设计目标就是确保数据生产到Kafka的主题后，对多个应用场景都是可用的。这种情况下，我们希望每个应用程序都能够得到所有的消息，而不是消息子集。为了确保一个应用程序得到主题的所有消息，应该保证每个应用程序都有单独的消费者组。不同于很多传统的消息系统，Kafka可以在不牺牲性能的前提下大规模扩展地消费者和消费者组。  

在前面的示例中，如果我们新添加一个只有一个消费者的消费者组G2，那么G2中的这个消费者就会得到主题T1的所有消息，而它和消费组G1在做什么事情毫无关系。消费者组G2也可以拥有多个消费者，每个消费者也可以获得所有分区的一个子集，就像我们前面所说的G1一样，但是从整体上来说消费组G2仍然会得到所有的消息，而不会受其他消费者组的影响。  
![image](/Images/Kafka/consumer-and-consumer-groups-5.png)  

总结下上面的操作过程，你为每个需要读取一个或多个主题所有消息的应用程序都创建了新的消费组，然后为已有的消费组添加消费者来动态地扩展从主题中读取和处理消息的能力，那么每个新增加的消费者都只能得到消息的子集。  

#### 消费者组和分区平衡  
正如我们前面看到的，一个消费者组中的消费者共享它们所订阅的主题的所有分区。当我们为消费者组添加新消费者时，它会从之前其他消费者消费的分区开始消费消息。同样当发生消费者关闭、进程挂掉、离开消费组，它所使用的分区就会被其他剩余的消费者所消费。为消费者重新分配分区同样也会发生在消费组订阅的主题被修改时(比如管理员添加一个新的分区)。  

分区的所有权从一个消费者转移给另一个消费者被称作为平衡(rebalance)。平衡操作是非常重要的，因为它提供了消费者组的高可用、可扩展性(允许我们更简单和安全的添加和删除消费者)，但是在通常情况下，事件则相当的不受欢迎。在平衡期间，消费者不能消费消息，所以平衡从根本上说是消费者组短暂的不可用窗口。另外，当分区从一个消费者转移到另一个消费者时会丢失当前的状态，如果它缓存了数据的话，就需要重新刷新缓存——这会使得应用程序响应变慢，直到消费者重新恢复到正常的状态。本章我们会讨论如何安全地处理平衡操作，并且怎么避免不必要的平衡。  

消费者为了维护它们在消费组中的成员地位，以及分配给它们的分区的所有权，它们是通过发送心跳给被指定为消费者组协调者(Group Coordinator)的Kafka broker(这个broker对于不同的消费组可能是不同的)。只要消费者能够在正常的时间间隔内发送心跳，它就会被认为是活着的、运行良好的，并且可以处理分配给它的分区消息。当消费者轮询的时候(比如检索消息)以及当它提交它消费的消息时就会发送心跳。  

如果消费者很长时间没有发送心跳，它的会话会超时，进而消费者组协调者将会认为消费者死亡，并且从而触发一次平衡操作。如果消费者崩溃并且停止处理消息，协调者会在数秒内没有心跳消息，进而决定它挂掉了并且触发平衡。在这数秒的时间段内，挂掉的消费者拥有的分区上不会处理任何消息。而如果是优雅地关闭一个消费者时，消费者会通知消费者组协调者说它正在离开，协调者就会立刻触发平衡，从而减少了消息无法被处理的间隔。本章的后面我们会讨论一些关于控制心跳频率、会话超时的配置，以及如何设置它们来匹配我们的需求。  

**Kafka新版本中对心跳改变**  
在Kafka 0.10.1版本中，Kafka社区介绍了独自的心跳线程，它将会在轮询期间也会发送心跳。这将允许你从轮询的频率中将心跳的频率分离出来。在Kafka的最新版本中，

**如何为消费者分配Partition**  
当一个消费者想要加入一个消费者组，它会发送JoinGroup请求给消费者组的协调者。第一个加入消费者组的消费者会成为组的领导者(Leader)。领导者会从协调者那里接收到一个包含组内所有消费者的列表(这个列表包括了最近发送了心跳，被认为是存活的所有消费者)，并且负责为每个消费者分配分区子集。它会使用PartitionAssignor接口的实现来决定哪个分区应该被哪个消费者处理。  

Kafka内置了两种分区分配策略，我们将会在配置部分会详细介绍。在决定了分区的分配之后，消费者领导者会发送分配列表给协调者，协调者会发送这些分配信息给所有的消费者。每个消费者只会看到它自己的分配结果——领导者是消费者组内唯一有所有消费者列表和它们的分配信息的客户端进程。这个过程在每次平衡操作发生时都会重复执行。  

### 创建一个消费者  
开始消费记录的第一步是创建一个KafkaConsumer实例。创建KafkaConsumer与创建KafkaProducer是非常类型的——首先需要创建一个带有你想要传递给消费者的配置属性的Properties实例。本章后面我们将会深入讨论所有的属性。这里我们只需要三个必须的属性：bootstrap.servers、key.deserializer和value.deserializer。  

第一个属性bootstrap.servers是指向Kafka集群的连接字符串。它和KafkaProducer的使用方式一样(你可以参考第3章对于它如何使用的详细定义)。其他两个属性key.deserializer和value.deserializer和生产者中定义的serializers类似，但是你需要指定可以获取字节数组并将其转换为Java对象的类，而不是指定将Java对象转换为字节数组的类。  

还有第四个严格意义上说非必要的属性，但现在我们假设它是必须的。这个属性就是group.id，它指定了KafkaConsumer实例所所属的消费者组。虽然创建不属于任何消费者组的消费者也是可行的，但这种情况很少见，所以本章我们都会假设消费者是消费者组的一部分。  

下面的代码片段展示了如何创建一个KafkaConsumer：  
```java
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
```  
如果你读过第3章创建生产者的代码，你会发现这里看到的大部分代码都很熟悉。假设我们消费的消息格式中key和value都是字符串类型。仅仅新的属性group.id可能你没见过，它是这个消费者所属的消费者组名称。  

### 订阅主题  
一旦我们创建完消费者，下一步是让消费者订阅一个或多个主题。subscribe()方法会将主题的列表作为一个参数，因此它使用起来非常简单：  
```java
consumer.subscribe(Collections.singletonList("customerCountries"));
```  

1. 这里我们简单的创建了只有一个元素的列表：主题为"customerCountries"。  

也可以使用正则表达式调用subscribe方法。正则表达式可以匹配多个主题名称，如果有人创建了和正则表达式匹配的新主题，平衡操作基本上会立即发生，并且消费者就会从新主题中开始消费。这种方式对于需要从多个主题消费消息的应用程序非常有用，而且可以处理不同主题包含的不同类型的数据。使用正则表达式订阅多个主题普遍被用于那些在Kafka和其他系统之间复制数据的应用。  

为了订阅所有的test主题，我们可以调用：  
```java
consumer.subscribe("test.*");
```  

### 轮询循环  
消费者API的核心是一个简单的循环，为了轮询服务端拉取更多的数据。一旦消费者订阅了主题，轮询循环会处理所有的协调细节、分区平衡、心跳、数据获取，仅仅留给开发者的简洁的API，可以方便的返回分配分区的可用数据。消费者代码的主体如下：  
```java
try {
  while (true) { //1
    ConsumerRecords<String, String> records = consumer.poll(100); //2
    for (ConsumerRecord<String, String> record : records) { //3
      log.debug("topic=%s,partition=%s,offset=%d,customer=%s,country=%s\n",
        record.topic(), record.partition(),
        record.offset(), record.key(), record.value());

      int updatedCount = 1;
      if (custCountryMap.countainsValue(record.value())) {
        updatedCount = custCountryMap.get(record.value()) + 1;
      }
      custCountryMap.put(record.value(), updatedCount)

      JSONObject json = new JSONObject(custCountryMap);
      System.out.println(json.toString(4)) //4
    }
  }
} finally {
  consumer.close(); //5
}
```  
1. 这里确实是一个死循环，消费者通常都是长时间运行的应用程序，会持续从Kafka中拉取数据。后面的章节我们会展示如何干净地退出循环，并且关闭消费者。  

2. 这是本章最重要的一行代码。就像鲨鱼要么保持不断游动要么死亡，消费者必须持续轮询Kafka，否则就会被认为挂掉，并且它消费的分区将被交给组中其他的消费者继续处理。传递给poll()方法的参数是一个超时间隔，用于控制如果消费者缓冲区的数据不可用，poll()将会阻塞多久。如果设置为0，那么poll()方法会立即返回；否则，poll()会在指定时间间隔内会一直等待消费者从broker中获取数据。  

3. poll()方法返回一个记录集。每条记录会包含这条记录来源于哪个主题和分区、这条记录在分区中的偏移量、当然还有这条记录的键值。通常我们会想要迭代列表，并且处理每一条单独的记录。poll()方法也可以接受一个超时时间参数，用于指定轮询最多花费多长时间后返回，不管有没有数据。这个超时时间通常由应用程序是否需要快速响应来决定——轮询之后多快返回对主线程的控制。  

4. 消息处理最后通常会写入一个结果到数据存储系统或者更新已有的记录。这里，我们的目标是为了持续获取每个国家的顾客数量，因此我们更新一个字典表并且将结果打印为JSON。实际应用中一般会将更新记录写入到存储系统中。  

5. 在退出前总是会执行close()方法，关闭消费者。这会关闭网络连接和Socket。它同样也会立即触发一次平衡操作，而不是让协调者来发现消费者可能因为挂掉而没有及时发送心跳，那样会等待更长的时间，也会导致分区子集的消息在更长的时间内不能被任何消费者所消费。  

轮询操作做了比仅仅是获取数据更多的工作。当新的消费者第一次调用poll()方法时，它会负责找到GroupCoordinator，加入消费者组，并且接收分区的分配。如果平衡操作被触发，也是在轮询内部处理的。当然用来表示消费者存活状态的心跳也是在轮询内部发送的。基于这些原因，我们要确保迭代处理消息时要足够快速和高效。  

**线程安全**：你不可以在一个线程中拥有同一个消费者组的多个消费者，而且也不能在同一个消费者中使用多线程。一个线程对应一个消费者是最基本的原则。在一个应用程序中运行同一个消费者组的多个消费者，你需要保证每个消费者运行在自己的线程中。将消费者的逻辑包装在它自定义的对象中是非常有用的，然后使用Java的ExecutorService来启动各自的消费者线程。Confluent的博客给出了具体实践。  

### 消费者配置  
目前为止我们主要专注于学习消费者API的使用方法，但我们只看到了很少的配置属性——仅仅只有那些必须的bootstrap.servers、group.id、key.deserializer和value.deserializer。所有的消费者配置属性在Kafka官方文档中都有给出。大部分参数都有一个合理的默认值，并不要求修改，但是有些参数可能会影响消费者的性能和可用性。下面让我们看一下这些比较重要的配置。  

#### fetch.min.bytes  
该属性允许消费者指定从broker端拉取记录时想要接受的最小数量。如果一个broker接收到一个消费者的拉取记录请求，但是新的记录的字节数小于min.fetch.bytes，那么broker在发送记录给消费者之前会等待直到有更多可用的消息。这种方式可以减少消费者和broker的负载，因为万一主题没有太多的活动数据(或者一天中的低峰期)，他们处理的消息来回次数更少。当没有太多的数据可以消费，但消费者却使用了很多的CPU，你可以将该参数设置的比默认值更大一点，这样当你有很多消费者的情况下，也可以减少服务端的负载。  

#### fetch.max.wait.ms  
通过设置fetch.min.bytes，告诉Kafka直到有足够的数据才发送响应给消费者。fetch.max.wait.ms则允许你控制最多等待多长的时间。默认情况下，Kafka会等待500ms。假如没有足够的数据流入Kafka主题以满足最小返回的数据量，这将会导致了500ms额外的延迟。如果你想要限制潜在的延迟(通常是由应用程序的SLA控制最大的延迟时间)，你可以将fetch.max.wait.ms设置为一个更小的值。假设你将fetch.max.wait.ms设置为100ms，将fetch.min.bytes设置为1MB，Kafka从消费者那里接受到拉取数据的请求后，要么当有1MB的数据量要么在100ms之后，无论哪个条件先达到，都会返回响应。  

#### max.partition.fetch.bytes  
这个属性控制了服务器端每个分区返回的最大字节数。默认值是1MB，这就意味着当KafkaConsumer.poll()返回的ConsumerRecords，分配给每个消费者的分区最大只能使用记录集对象的max.partition.fetch.byte。因此假如一个主题有20个分区，你有5个消费者，每个消费者将需要4MB的可用内存提供给ConsumerRecords对象。实际中你应该为每个消费者分配更多的内存，因为消费者组中的其他消费者失败时，没有失败的消费者需要处理更多的分区。max.partition.fetch.bytes需要比broker能接受的最大消息大小(由broker配置max.message.size决定)还要大，否则broker中可能就会有些消息无法被消费者所消费，在这种情况下，消费者在尝试读取比较大的消息时处于悬挂状态。当设置max.partition.fetch.bytes的时候另一个重要的衡量标准是消费者处理数据花费的时间。正如你所知道的，消费者必须足够频繁地调用poll()方法来避免会话超时和后面的平衡。如果调用一次poll()返回的数据非常大，消费者可能需要花费很长的时间去处理，也就意味它将无法及时地进入下一次轮询循环的迭代来避免会话超时。如果这种情况发生了，有两种可选解决方案，要么降低max.partition.fetch.bytes要么增加会话的超时时间。  

#### session.timeout.ms  
该配置表示消费者在一段时间内不需要和代理节点联系也仍然认为是存活的，默认值是3秒。如果消费者超过session.timeout.ms时间还没有发送心跳给协调者，消费者就会被认为挂掉。协调者会触发一次消费组的平衡，并将属于挂掉的消费者的分区分配给消费组中其他的消费者。该配置和heartbeat.interval.ms密切相关。heartbeat.interval.ms会控制每隔多长时间消费者的poll()方法会发送一次心跳给协调者，而session.timeout.ms则控制消费者在没有发送心跳时多久会离开消费组。因此这两个配置通常一起修改，而且heatbeat.interval.ms必须要比session.timeout.ms低，通常心跳间隔会设置为超时时间的1/3。比如session.timeout.ms设置为3秒，那么heartbeat.interval.ms就应该设置为1秒。将session.timeout.ms设置的比默认值要低时，允许消费组更快地检测和恢复故障。但同时也会造成不必要的平衡，比如消费者可能花费比较长的时间完成一次轮询调用或者正在发送垃圾回收，而并没有真正挂掉，但是因为会话超时时间很短，导致发生更频繁的平衡。如果设置session.timeout.ms太大了，虽然可以减少偶然的平衡，但同时也意味着要花费更长的时间才能检测到真正的错误。  




















#### auto.offset.reset  
该配置控制了消费者在一个没有提交的偏移量，或者偏移量是无效（通常是因为消费者挂掉太长的时间，带有偏移量的那条记录对于代理节点而言太旧了）的分区上，如何开始读取数据的行为。默认值是“最近的”（latest），表示在没有有效偏移量的情况下，消费者会从最新的记录开始读取（在消费者开始运行之后才被写入的记录，如果说消费者还没正式运行，即使写入记录，在消费者正式启动之后也不会被读取到，只从消费者正式启动的那一刻之后的记录才会被读取）。另外一种选择方式是“最早的”（“earliest”），表示在没有有效的偏移量时，消费者会从分区的最开始读取所有的数据。  

#### enable.auto.commit  
本章我们已经讨论了提交偏移量的不同方式。这个参数控制了消费者是否会自动提交偏移量，默认值为true。如果你想要自己控制什么时候提交偏移量，可以设置为false。这对于减少数据的重复处理以及避免丢失数据是非常有必要的。如果你设置了enable.auto.commit为true，你通常也会使用auto.commit.interval.ms来控制多长时间提交一次偏移量。  

#### partition.assignment.strategy  
我们知道分区被分配给一个消费组中的所有消费者。PartitionAssignor类的作用是：给定消费者和它们订阅的主题，它来决定哪个分区应该被分配给哪个消费者。默认Kafka有两种分配策略：平行（Range）：分配给每个消费者的是，从它订阅的每个主题中连续的分区子集。举例消费者C1和C2都订阅了两个主题：T1和T2，这两个主题每个都有3个分区。那么消费者C1会分配到T1和T2主题的分区0和分区1，而消费者C2只会分配到这两个主题的分区2。注意由于每个主题的分区数量是奇数的，而且每个主题的分配都是独立的，所以第一个消费者会比第二个消费者分配到更多的分区。使用Range分配方式，当消费者的数量不能整除每个主题的分区数时就会发生这种情况。
轮询分配（RoundRobin）：从所有订阅主题的所有分区中一个接一个顺序分配地分配给所有的消费者。以上面的两个消费者C1和C2为例，使用RoundRobin分配策略时，消费者C1会得到主题T1的分区0和分区2，以及主题T2的分区1；而消费者C2会得到主题T1的分区1，以及主题T2的分区0和分区2。通常情况下，如果所有的消费者订阅了相同的主题（这是很常见的场景），采用轮询分配的方式时，最终所有消费者都会分配到相同数量的分区（或者说最多有一个分区是不同的）。
partition.assignment.strategy配置允许你选择一个分区的分配策略。默认是实现了Range策略的org.apache.kafka.clients.consumer.RangeAssignor类，你也可以替换成org.apache.kafka.clients.consumer.RoundRobinAssignor类。当然你也可以实现自定义的分配策略，这种情况下应该将partition.assignment.strategy指向你自定义的类路径。  

#### client.id  
This can be any string, and will be used by the brokers to identify messages sent from the client. It is used in logging, metrics and for quotas.
该设置可以是任何的字符串，它会被用在代理节点定位消息是从哪个消费者客户端发送的，通常用在日志记录，性能监控，限额等。  

#### max.poll.records  





#### receive.buffer.bytes和send.buffer.bytes



### 提交和偏移量  
无论什么时候我们调用poll()方法时，它会返回已经写入到Kafka，但是消费组的消费者还没有读取的记录。这就意味着我们需要有一种方式来跟踪消费者读取到了哪条记录。前面讨论过，Kafka不同于其他消息系统的一个独有特性是，它不会从消费者中跟踪应答。相反，它允许消费者使用Kafka来跟踪每个分区的位置（偏移量）。我们把更新分区中当前位置这个动作叫做提交（commit）。
那么消费者如何提交偏移量呢？它会往Kafka的一个特殊主题__consumer_offsets生产消息，这个主题保存了每个分区的提交位置。只要你的消费者是存活的、正在运行，也不会对它有任何影响。但是如果消费者挂了或者新消费者加入消费组，就会触发平衡。在平衡过后，每个消费者可能会被分配到和之前所处理的不同的新分区集合。为了明确要从哪里开始工作，消费者会读取每个分区最近的提交位置，然后从那个位置继续。
如果分区的提交位置比消费者客户端处理的最近一条消息的位置要小，那么在最近处理消息的位置和提交位置之间的消息就会被（消费者）处理两次。

相反如果提交位置比消费者实际处理的最近一条消息位置大，那么这两个位置中间的所有消息就都不会被消费组处理了（当然我们要尽量避免这种丢数据的场景）。

可见对偏移量（即上文说的位置）的管理对客户端应用程序而言影响很大。KafkaConsumer的使用接口提供了多种提交偏移量的方式。

#### 自动提交偏移量  
提交偏移量最简单的方式是让消费者为你做这件事情。如果你设置了enable.auto.commit=true，那么每隔5秒消费者就会提交客户端轮询结果的最大偏移量。5秒是一个默认值，通过配置项auto.commit.interval.ms控制。就像消费者的其他逻辑一样，自动提交偏移量也是由poll()轮询驱动的。当你调用poll()轮询时，消费者会检查是否可以开始提交，如果需要提交，就会在最近一次轮询返回时提交偏移量。不过，在使用这个简便的选项之前，理解这种方式的一些不良后果是非常重要的。

考虑默认场景下自动提交会每隔5秒发生一次。假设在最近一次提交过后3秒发生了一次平衡操作。平衡过后所有的消费者都会从上次最近提交的偏移量开始消费。这种场景下偏移量是3秒之前的了，这就会导致在这3秒内到达的所有事件都会被处理两次。尽管可以设置更短的提交间隔，以便更频繁地提交，减少消息被重复处理的窗口，但还是无法从根本上彻底解决数据重复处理的问题。
注意在开启自动提交时，调用poll总是会提交上一次poll的最近偏移量。但是它并不知道都实际处理了哪些事件，所以客户端应该总是要保证在调用新的poll之前要处理上一次poll返回的所有事件（或者在调用close之前，也会自动提交偏移量）。通常这不是一个严重的问题，但在处理异常或者过早地退出轮询循环时需要特别注意。
自动提交偏移量非常方便，但是它的缺点也很明显：它不能够给予开发者足够的控制权来避免消息的重复处理。


#### 提交当前偏移量  
大多数开发者都希望在定时提交偏移量上能够对偏移量有更多足够的掌控能力，他们的想法不仅仅是要消除丢失数据的可能性，也希望在平衡发生时减少消息的重复处理数量。消费者API提供了在某个点上提交当前偏移量的选项，相比基于定时器的自动提交方式，这种方式对应用程序开发者而言更有意义。
通过设置auto.commit.offset=false，偏移量只会在应用程序显示调用时才会被提交。最简单和可靠的提交API是commitSync()方法。该API会提交poll()返回时的最近偏移量，并且一旦偏移量被提交后就会返回，如果因为某种原因提交失败了则会抛出异常。
注意commitSync()提交的会对poll()返回时提交这批数据的最近偏移量，所以要确保处理完集合中的所有记录后才调用commitSync()，否则你就会面临前面提到的丢失数据问题（先提交偏移量然后才处理记录，如果处理某条记录失败了，这条失败的记录以及之后的记录都不会有机会被处理）。当触发平衡时，从最近一批记录的最开始直到发生平衡这个时间点的所有消息都会被处理两次（消息重复处理仍然不可避免，比如处理顺序为：提交偏移量=5，拉取一批消息共10条，然后开始处理记录，假设只处理了3条就发生了平衡，平衡之后，消费者会重新从位置5开始处理，所以这批消息的开始到发生平衡时的3条记录就会被重新处理）。
下面的代码示例中，一旦在处理完最近的一批数据后，使用commitSync()方法提交偏移量：  
```java
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(100);
  for (ConsumerRecord<String, String> record : records) {
    println("topic=%s,partition=%s,offset=%d,customer=%s,country=%s",
      record.topic(), record.partition(),
      record.offset(), record.key(), record.value()); //1
  }
  try {
    consumer.commitSync(); //2
  } catch (CommitFailedException e) {
    log.error("commit failed", e) //3
  }
}
```  
这里假设打印一条记录的内容表示已经处理完了该记录。你实际的应用程序肯定比这要复杂，你应该根据你的实际用例决定什么时候记录被处理完成。
一旦处理完了这一批的所有记录，我们调用了commitSync()提交这一批的最近偏移量，并且这个操作发生在下一次轮询拉取新消息之前。
在没有不可恢复的错误下，调用commitSync()提交偏移量失败应该重试，这里只记录错误日志。

#### 异步提交偏移量  
手动提交的一个缺点是应用程序会在代理返回提交请求的响应之前一直被阻塞（客户端向Kafka的代理节点发送提交偏移量请求，在这期间，应用程序无法执行其他业务逻辑），这会直接限制了应用程序的吞吐量。虽然可以通过频度更少的提交来提高吞吐量，但代价是在发生平衡时增加了重复处理的可能性。
另外一个选项是异步提交API，我们发送完提交请求后继续后续的业务逻辑处理，而不需要等待代理节点返回提交响应。commitAsync()方法会提交偏移量，然后继续向下运行（即开始新的轮询）。  
```java
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(100);
  for (ConsumerRecord<String, String> record : records) {
    //处理记录，比如简单的打印，略
  }
  consumer.commitAsync(); // 1
}
```  
同步的commitSync()方法缺点是如果提交成功会一直尝试提交，或者在遇到无法重试的场景下才会结束，但异步的commitAsync()方法不管有没有执行成功都不会重试。不需要重试的原因是当commitAsync()接收到服务端的响应时，可能已经存在一个更新的提交已经成功了。假设我们发送了一个要提交偏移量为2000的请求，但是由于临时的通信问题，代理节点从来就没有机会收到这个请求，所以也就不会发送响应。同时我们处理了新的一批数据，并且成功地提交了偏移量=3000。如果第一次的commitAsync()由于提交失败现在执行重试，它这是可能也会成功地提交了偏移量=2000，但实际上偏移量=3000已经完成并提交成功了，在平衡的场景下，这种场景会导致更多的重复处理。
我们提到的这种混乱主要是为了让大家知道提交顺序的重要性，commitAsync()方法还提供了自定义的处理作为回调函数传入，自定义的回调函数会在代理返回响应时触发执行。通常会使用回调函数记录提交错误或者在监控系统中计数，但如果你要用回调来做重试的话，你就需要担心提交顺序的问题。下面的代码中我们发送了提交请求，然后继续，但如果提交发生失败，会记录失败的偏移量，以及异常原因。  
```java
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(100);
  for (ConsumerRecord<String, String> record : records) {
    //处理记录，比如简单的打印，略
  }
  consumer.commitAsync(new OffsetCommitCallback() {
    public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets,
                           Exception exception) {
      if (e != null) log.error("Commit failed for offsets {}", offsets, e);
    }
  }); //1
}
```  
保证异步重试时提交顺序的正确性，可以使用单调递增的序号。每次提交时增加序号，并且在异步提交的回调里执行成功时也增加序号。当你准备重试时，检查回调总的提交序列号是否和实例变量的相同，如果相同，说明没有新的提交，那么就可以安全地重试。但如果实例变量比回调的序号要搞，就不需要重试，因为新的提交已经发送出去了。


#### 结合同步和异步提交  
通常，偶然性出现提交故障并不是一个大问题，因为如果这个问题是短暂的，后续的提交也会成功。但如果在关闭消费者之前，我们确切地知道这就是最后一次提交了，或者在发生平衡之前，我们都要确保提交必须成功。

因此一种普遍的做法是在关闭之前结合使用commitAsync()和commitSync（后面我们会在谈到平衡监听器时讨论怎么在平衡之前提交），做法如下：  
```java
try {
  while (true) {
    ConsumerRecords<String, String> records = consumer.poll(100);
    for (ConsumerRecord<String, String> record : records) {
      //处理记录，略
    }
    consumer.commitAsync(); //1
  }
} catch (Exception e) {
  log.error("Unexpected error", e);
} finally {
  try {
    consumer.commitSync(); //2
  } finally {
    consumer.close();
  }
}
```  
当一切工作的很正常时，我们使用异步的commitAsync，它很快，而且如果一次提交失败了，下一次会重试
在关闭消费者时，不会有下一次提交了，我们就调用同步的commitSync，它会重试直到提交成功



#### 提交指定偏移量  
提交最近的偏移量只会允许你在处理完批记录后才会提交，但如果你想要更频繁地提交呢？如果说poll()返回的是一批很大的记录集，你想要在这批记录集的中间某个位置提交偏移量，避免在平衡发生时不得不重新处理这些所有的记录？你不能仅仅调用commitSync()或者commitAsync()，它们只会提交返回的最近偏移量，而返回的这些记录你都还没有执行。
幸运的是，消费者API允许你调用commitSync()和commitAsync()时传递一个你希望提交的分区和偏移量的字典。如果你已经处理了一批记录的中间，并且你从主题为“客户端”的分区3得到的最近一条消息的偏移量=5000，你可以立即调用commitSync()来提交主题为“客户端”分区3的偏移量。由于你的消费者可能会消费多个分区，你需要跟踪所有分区的偏移量，所以用这种更细粒度的方式控制偏移量的提交会增加你的代码的复杂性。下面是提交指定偏移量的代码片段：  
```java
Map<TopicPartition, OffsetAndMetadata> currentOffsets; //1
int count = 0;
....
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(100);
  for (ConsumerRecord<String, String> record : records) {
    //处理逻辑，略 //2
    currentOffsets.put(new TopicPartition(record.topic(),record.partition()),
                       record.offset()); //3
    if (count % 1000 == 0)   //4
      consumer.commitAsync(currentOffsets); //5
    count++;
  }
}
```  
我们使用这个Map字典结构用来手动跟踪偏移量
这里用打印记录的方式代替实际的业务处理
读取完每条记录后，用最近的偏移量更新偏移量字典
这里我们决定每隔1000条记录提交一次，实际应用中可以根据时间提交甚至是记录内容
这里选择调用commitAsync，不过commitSync也同样有效。当然提交指定的偏移量，也仍然需要处理前面章节中提到的错误。



### 平衡监听器  
前面章节中说过提交偏移量时，消费者会在分区平衡之前或者退出时执行一些清理工作。如果你知道消费者即将失去一个分区的所有权，你应当要提交已处理完最近事件的偏移量。如果你的消费者维护了一个事件缓冲区，并且偶尔才会处理一次（比如在使用pause()功能时会使用currentRecords字典暂存记录），你也应当在失去分区的所有权之前处理目前为止收集的所有事件。也许还需要做其他的工作比如关闭文件句柄，释放数据库连接等等。
消费者API允许你在消费者所属的分区被添加和移除时，运行自定义的代码逻辑。可以通过在调用subscribe()方法时传递一个ConsumerRebalanceListener监听器来完成，该监听器接口有两个需要的方法：
public void onPartitionsRevoked(Collection<TopicPartition> partitions)会在平衡开始之前以及消费者停止消费消息之后调用。在这里通常要提交偏移量，这样无论下一个消费者是谁，它获得到分区后，就知道要从哪里开始。
public void onPartitionsAssigned(Collection<TopicPartition> partitions)会在分区重新分配给消费者之后，在消费者开始消费消息之前调用。
下面的示例展示了如何使用onPartitionsRevoked()方法在失去一个分区的所有权之前提交偏移量。后面我们会展示同时模拟使用了onPartitionsAssigned()方法的更复杂示例。  
```java
private Map<TopicPartition, OffsetAndMetadata> currentOffsets;

private class HandleRebalance implements ConsumerRebalanceListener { //1
  public void onPartitionsAssigned(Collection<TopicPartition> partitions){//2
  }

  public void onPartitionsRevoked(Collection<TopicPartition> partitions) {
    consumer.commitSync(currentOffsets); //3
  }
}

try {
  consumer.subscribe(topics, new HandleRebalance()); //4

  while (true) {
    ConsumerRecords<String, String> records = consumer.poll(100);
    for (ConsumerRecord<String, String> record : records) {
      //处理记录，略
      currentOffsets.put(
            new TopicPartition(record.topic(), record.partition()),
            record.offset());
          }
              consumer.commitAsync(currentOffsets);
            }
          } catch (WakeupException e) {
            // ignore, we're closing
          } catch (Exception e) {
            log.error("Unexpected error", e);
          } finally {
            try {
              consumer.commitSync(currentOffsets);
            } finally {
              consumer.close();
            }
          }
```  
我们从实现ConsumerRebalanceListener监听器开始
本例中，在分配到新分区之后我们没有做任何事情，接下来只是消费消息而已
然而，由于平衡导致失去分区的控制权时，需要提交偏移量。注意我们提交的是已经处理完的消息的最近偏移量，而不是当前一批仍然在处理的最近偏移量，因为在处理一批记录的中间也有可能分区被取消（这样可以最大限度地减少平衡之后重复处理的数据量，但还是不可避免数据重复）。同时我们会提交所有分区的偏移量（属于当前消费者的），而不是我们即将失去的某些分区，因为currentOffsets字典针对的是所有已经处理完的事件，所以这并没有什么大的影响。最后，我们使用了同步的syncCommit来确保在平衡发生时成功地提交了偏移量。
最重要的一部分，将步骤1创建的监听器传递给subscribe()方法，这样就可以被消费者调用



### 消费指定Offset的记录  






### 如何退出  



### 反序列化器  




#### 自定义反序列化器  




#### Avro反序列化  





### 独立的Consumer：为什么和如何不使用带有group的Consumer  





### 旧的Consumer APIs  




### 总结
