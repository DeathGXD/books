每个企业都是由数据进行驱动的。我们从数据中获取信息，分析它，处理它，并且创造更多的产出。每个应用都会产生数据，不论是日志消息，指标，用户行为，输出报文或者其他类型。数据的每个字节都有它的作用，告诉我们接下来应该做哪些重要的事。为了知道数据的意义，我们需要从数据生成的地方获取数据，并将数据传输到可以分析的地方。  




### 发布/订阅消息  
在讨论Kafka相关概念之前，理解发布/订阅消息的相关概念和明白为什么它是重要的是非常关键的。发布/订阅消息队列的特征是消息的sender(publisher)并不直接将data(message)发送给receiver，publisher以某种方法对消息进行分类，而receiver(subscriber)会订阅接受特定类别的消息。Pub/Sub系统通常会有broker(消息被发布到的中心点)来进行实现，消息将被发送至broker。  

#### 由来
许多发布订阅用例都始于相同的方式：利用一个简单的消息队列或者进程间的通信。比如：你编写的应用程序需要向某处发送监控信息，你可以从应用程序直接连接到显示监控数据的dashboard，并通过该连接发送监控数据，如图1-1所示：  


不就之后，你决定要分析长期的数据，但在dashboard中展示的效果不是很好，于是你建立了一项新服务，可以接受监控、存储指标并对其进行分析。为了支持此功能，你可以修改应用程序以将指标写入这两个系统(实时监控和长期监控)。到目前为止，有多于三个的应用程序生成指标信息，并且它们都利用相同的连接和两个服务建立连接。你的同事认为，对服务器进行轮询以用于产生报警也是个不错的想法，因此你在每个应用服务器添加根据请求提供指标的服务。过一段时间后，你将会有更多应用程序需要使用这些服务器去获取各个指标并将其用于各种目的。现在的架构看起来可能如图1-2所示，连接变得更加复杂，难以跟踪调试。  
![]()  

很明显到这里已经欠了很多技术债，你决定偿还一些回来。你使用一个应用程序接受来自所有应用程序的指标，并提供一个服务器来查询任何它们需要的系统的指标。这样就降低了架构的复杂性，类似于图1-3。恭喜，你已经构建了一个发布订阅系统！  
![]()  



####　单队列系统  
在你与监控这场战争中，你的一个同事也一直在对日志消息进行类似的工作。另一个则是在跟踪前端页面上的用户行为，并向正在从事机器学习的开发人员提供该信息，为管理层创建一些报表。你已经遵循了类似的方法来构建将消息的发布者与消息的订阅者解耦的系统。图1-4显示了这种结构，具有三个独立的发布/订阅系统。  
![]()  

这肯定比之前点对点的连接好多了(图1-2所示)，但是有很多重复的工作。你的公司需要维护多个队列系统来存储数据，所有这些都有各自的bug和使用限制。你肯定也知道未来有更多需要消息队列的情况。你想要的是一个单一的集中式系统，允许发布通用类型的数据，并且能随着业务的增长而增长。  


### 初识Kafka  
Apache Kafka是一个基于分布式日志提交机制设计的发布订阅系统。数据在Kafka中持久化，用户可以随时按需读取。另外数据以分布式的方式存储，提供容错性，易于扩展。  


#### Message和Batches  
Kafka中最基本的数据单元是消息message，如果使用过数据库，那么可以把Kafka中的消息理解成数据库里的一行或者一条记录。消息是由字符数组组成的，Kafka并不关心它内部是什么，索引消息的具体格式与Kafka无关。消息可以有一个可选的key，这个key也是一个字符数组，与消息一样，对于Kafka也是透明的。key用来确定消息写入分区时，进入哪个分区。最简单的处理方式，就是把key作为hash串，拥有相同key的消息，肯定会进入同一个分区。  

为了提供效率，Kafka以批量的方式写入。一个batch就是一组消息的集合，这一组的数据都会进入同一个topic和partition(这个是根据producer的配置来定的)。每一个消息都进行一次网络传输会很消耗性能，因此把消息收集到一起，再同时处理就高效多了。当然，这样会会引入更高的延迟和吞吐量：batch越大，同一时间处理的消息就越多。batch通常都会进行压缩，这样在传输和存储的时候效率都会更高一些。  

#### Schema  
对于Kafka来说，消息本身是不透明的，这样就能对消息定义更多容易理解的内容。根据个人需求的不同，消息都会有不同的schema。比如JSON或者XML都是对人来说很容易阅读的格式。然后它们在不同的模式版本中间缺乏一些处理的鲁棒性和可扩展性。一些Kafka的开发者也倾向于使用Apache Avro(最开始是用来为Hadoop做序列化的)，提供了紧凑的序列化格式，在发生变化时，也不需要重新生成代码，具有很强的数据类型和模式，具有很好的向前扩展和向后兼容的能力。  

Kafka中数据是连续的，数据在写入的同时也可能被读取消费，这样数据的格式就很重要了。如果数据格式发生变化，消费的应用也需要作出适当的调整。如果事先定义好了数据存储的格式，那么读取数据的时候就不需要做特殊的处理了。  

#### Topic和Partition  
消息都是以主题Topic的方式组织在一起，Topic也可以理解为传统数据库中的表，或者文件系统中的一个目录。一个主题由broker上的一个或者多个Partition分区组成。在Kafka中数据是以log的方式存储的，一个Partition就是一个单独的log。消息通过追加的方式写入日志文件，读取的时候则是从头开始按照顺序读取。注意，一个主题通常是由多个分区组成的，每个分区内部保证消息的顺序，分区之间是不保证顺序的。如果你想要Kafka中的数据按照时间的先后顺序进行存储，那么可以设置分区数为1。如下图所示，一个主题由4个分区组成，数据都以追加的方式写入这四个文件。分区的方式为Kafka提供了良好的扩展性，每个分区都可以放在独立的服务器上，这样就相当于主题可以在多个机器之间水平的扩展，相对于单独的机器，性能更好。  
![]()  

在Kafka这种数据系统中经常会提起stream流这个词，通常流被认为是一个主题中的数据，而忽略分区的概念。这就意味着数据流就是从producer到consumer。在很多框架中，比如kafka stream，apache samza，storm在操作实时数据的时候，都是这样理解数据流的。这种操作的模式跟离线系统处理数据的方式不同，如hadoop，是在某一固定的时间处理一批数据。  

#### Producer和Consumer  
Kafka中主要有两种使用者：Producer和Consumer。  

Producer用来创建消息。在发布订阅系统中，它们也被叫做Publisher发布者或writer写作者。通常情况下，消息都会进入特定的主题。默认情况下，生产者不关心消息到底进入到哪个分区，它会自动在多个分区之间进行负载均衡。也有的时候，消息会进入到特定的一个分区中。一般都是通过消息的key使用哈希的方式确定它进入哪一个分区。这就意味着如果所有的消息都给定相同的key，那么它们最终会进入同一个分区。生产者也可以使用自定义的分区器，这样消息就可以进入特定的分区。  

Consumer读取消息。在发布订阅系统中，也叫做subscriber订阅者或者reader阅读者。消费者订阅一个或者多个主题，然后按照顺序读取主题中的数据。消费者需要记录已经读取到消息的位置，这个位置也被叫做offset。每个消息在给定的分区中只有唯一固定的offset。通过存储最后消费的offset，消费者应用在重启或者停止之后，还可以继续从之前的位置读取。保存的机制可以是Zookeeper或者是Kafka自己。  

消费者是以Consumer Group消费者组的方式工作，由一个或者多个消费者组成一个组，共同消费一个topic。每个分区在同一时间只能由group中的一个消费者读取，在下图中，有一个由三个消费者组成的group，有一个消费者读取主题中两个分区，另外两个分别读取一个分区。某个消费者读取某个分区，也可以叫做某个消费者是某个分区的拥有者。  

在这种情况下，消费者可以通过水平扩展的方式同时读取大量的消息。如果一个消费者失败了，那么group中的其他成员会自动负载均衡读取之前失败的消费者读取的分区。  
![]()  


#### Broker和Cluster  
单独的Kafka服务器也叫作broker，Broker从生产者那里获取消息，分配offset，然后提交存储到磁盘中。他也会提供消费者，让消费者读取分区上的消息，并把存储的消息传给消费者。依赖于一些精简的资源，单独的broker也可以轻松的支持每秒数千个分区和百万级消息。  

Kafka的broker支持集群模式，在Broker组成的集群中，有一个节点也被叫做控制器(是在活跃的节点中自动选择的)。这个controller控制器负责整个集群的操作，包括分区的分配，失败节点的检测等。一个partition只能出现在一个broker，并且这个Broker也被叫做分区的leader。一个分区可以分配多个broker，这样可以做到多个 机器之间备份的效果。这种多机备份在其中一个broker失败的时候，可以自动选举出其他的broker提供服务。然而，producer和consumer都必须连接leader才能正常工作。  
![]()  

Kafka的一个重要个性就是支持数据的过期删除，数据可以在Broker上保留一段时间。Kafka的broker支持针对topic设置保存的机制，可以按照大小配置也可以按照时间配置。一旦达到其中的一个限制，可能是时间过期也可能是大小超过配置的数值，那么这部分的数据都会被清楚掉。每个topic都可以配置它自己的过期配置，因此消息可以按照业务的需要进行持久化保留。比如，一个数据追踪分析的topic可以保留几天时间，一些应用的指标信息则需要保存几个小时。topic支持日志数据的压缩，这样Kafka仅仅会保留最后一条日志生成的key。这在修改日志类型的时候非常有用。  


#### 多节点集群  




### 为什么选择Kafka  




#### 多生产者  




#### 多消费者  
